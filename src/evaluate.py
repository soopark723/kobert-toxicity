# -*- coding: utf-8 -*-
"""evaluate.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1nnyRgFtfgfIx7ukYPt5rLHs5LQenk3fo
"""

import torch
from torch.utils.data import DataLoader
from preprocessing import set_seed
from kobert_model import HateSpeechClassifier

def evaluate(model, dataloader, device, criterion):
    model.eval()
    total_loss = 0
    correct = 0
    total = 0

    with torch.no_grad():
        for batch in dataloader:
            input_ids = batch['input_ids'].to(device)
            attention_mask = batch['attention_mask'].to(device)
            labels = batch['labels'].to(device)

            outputs = model(input_ids, attention_mask)
            loss = criterion(outputs, labels)

            total_loss += loss.item()
            preds = torch.argmax(outputs, dim=1)
            correct += (preds == labels).sum().item()
            total += labels.size(0)

    avg_loss = total_loss / len(dataloader)
    accuracy = correct / total
    return avg_loss, accuracy

def run_evaluation(model_path, test_dataset, device, batch_size=32):
    set_seed()
    model = HateSpeechClassifier()
    model.load_state_dict(torch.load(model_path, map_location=device))
    model.to(device)

    test_loader = DataLoader(test_dataset, batch_size=batch_size)
    criterion = torch.nn.CrossEntropyLoss()

    loss, accuracy = evaluate(model, test_loader, device, criterion)
    print(f"Test Loss: {loss:.4f}, Test Accuracy: {accuracy:.4f}")